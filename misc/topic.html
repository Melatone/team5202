<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
  <title>Topic</title>
  <link rel="preconnect" href="https://fonts.googleapis.com"> 
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
  <link href="https://fonts.googleapis.com/css2?family=Gothic+A1:wght@400;700&display=swap" rel="stylesheet">
  	<link rel="stylesheet" href="../styles/mystyles.css">
  </head>

<body>
  
<!-- Site navigation menu -->

<div class="navbar" id="navbar">

  <a href="../index.html">Home page</a>
    <a href="topic.html">Technology/Topic</a>
    <a href="opportunities.html">Opportunities</a>
    <a href="risks.html">Risks</a>
    <a href="choices.html">Choices</a>
  <div class="dropdown">
    <button class="dropbtn">Ethical Reflections 
      <i class="fa fa-caret-down"></i>
    </button>
    <div class="dropdown-content">
      <a href="brandyn.html">Brandyn</a>
      <a href="mat.html">Mat</a>
      <a href="aidan.html">Aidan</a>
    </div>
  </div> 
  <div class="dropdown">
    <button class="dropbtn">Process Support 
      <i class="fa fa-caret-down"></i>
    </button>
    <div class="dropdown-content">
      
      <a href="references.html">References</a>

      <a href="meetings.html">Meeting Minutes</a>
      <a href="https://github.com/Melatone/team5202">Project Portfolio</a>
    </div>
  </div> 
</div>

<script>
    window.onscroll = function() {myFunction()};
    
    var header = document.getElementById("navbar");
    var sticky = header.offsetTop;
    
    function myFunction() {
      if (window.pageYOffset > sticky) {
      header.classList.add("sticky");
      } else {
      header.classList.remove("sticky");
      }
    }
    </script>
<!-- Main content -->
<h1>Computer Vision</h1>
<hr>


<p style="margin-left:10px;margin-right:70px;margin-bottom:0px;text-indent: 20px;">
  Computer Vision in short is the process of using AI or Deep-Learning to provide a computerized program "sight" in a more human sense of the word. This sense of sight is attained through multiple different types of
  Machine-Learning techniques that include but are not limited to Object Detection, Facial recognition, Edge Detection, Image Segmentation and Feature Matching. Using any combination of the different image-processing techniques,
  a computer is given the ability to describe very pertinent information contained in a photo or video, which can then be passed on to do a myriad of things.
 

</p>
<img src="../images/Screenshot-from-2019-03-28-11-45-55.png"  style="float:left;margin-top:10px;margin-bottom:10px;width:400px;margin-right: 10px" alt="Assessment Criteria Page One"> 

<h4>
  Image Segmentation/Edge Detection
</h4>
<p>
  Image segmentation is the most essential process for all AI photo recognition to function, either feature matching or Object Identification. Edge detection goes through an image pixel-by-pixel in clusters of about 9x9 and checks for the individual bit values of these pixels. In searching, the algorithm finds bit values of colors that differ drastically in color from the pixels surrounding it by multiplying these pixels bits by one of many different edge-detection transformation matrices. If a hard edge is found it classifies it as an edge and starts to create a composite image of the traced image. This process allows for only the most vital information about a picture to be simplified in terms of data and allows for point tracing such as feature matching or pattern recognition training in object identification. In the process of image segmentation, the edge finding algorithm is passed through an image multiple times, each time with an increasing amount of detail. The first run is done on a grey scaled photo will full "threshold" which is purely black and white with very little detail. Upon each run of edge finding, the number of colors and details are increased to smooth out the lines surrounding the objects in a photo. This process is instrumental to object identification as it allows to train the AI to focus on the right objects in a photo to learn the correct pattern recognition.</p>


<img src="../images/0_k--ZodnKi7ENH4MX.png"  style="float:right;margin-top:10px;margin-bottom:10px;width:300px" alt="Assessment Criteria Page One"> 
<h4 style = "float:right;margin-right:20px">
  Feature Matching/Facial Recognition
</h4>
<br>
<br>
<p style="margin-left:10px;margin-right:0px;margin-bottom:0px;text-indent: 20px;align:right">
  The process that predominately controls how facial AI facial recognition functions is feature matching. This system functions on the system of basic image processing systems such as edge detection as it is based primarily on "features" or something unique to a specific part of an image. Think of this as using a landmark on your trip to remember where something is. Using edge detection of sharp edges, points of dark and light, and sudden texture changes the AI maps out tens to thousands of these identifying "features". Once these features have been mapped out, each of the vector points is sent through an algorithm that translates each point into numerical data which acts as a fingerprint for the specified image. Once this image footprint is established, you can feed the feature matching or facial recognition algorithm any image for remote identification. A direct comparison of the fingerprint and the image is fed into the algorithm to find if it is the same. Because of how this fingerprint is created and used remotely removes the need for extensive AI training or databases of information. It is also because of these numerical values that there is enough flexibility built into the algorithm to allow for small variances in the 2 images returning a successful result. This is the technology used in most modern face scanners and fingerprint</p>
<br>


<img src="../images/IMG_4497.jpg"  style="float:left;margin-top:10px;margin-bottom:10px;width:200px" alt="Assessment Criteria Page One"> 
<img src="../images/download (10).jpeg"  style="float:left;margin-right:10px;margin-top:10px;margin-bottom:10px;width:200px"  alt="Assessment Criteria Page One"> 
<h4>
  Object Detection
</h4>
<p>
  Object Detection is the most universally known process of Computer Vision as it is the product of many sci-fi dystopian fictions. This algorithm unlike the rest needs a considerable amount of human interaction to make it functional. Based upon the algorithms of edge detection and image segmentation, an object identification AI can be "trained" into pattern recognition. By feeding an algorithm thousands of photos of a selected target, and the incremental self-correcting method of machine learning, you can define what a "cat" may look like, what a "person" may look like, and so on. Where this process differs from feature matching or any other identification process is that there is little to no room for failure; it is either extremely right or extremely wrong. In order to "teach" an effective identification of a cat, you must introduce all the potential variations. Despite extensive training, an object identification AI can still be easily fooled to return the values of both a car and a truck due to their similarities and how the AI was trained to identify each target. If trained extensively though, Object Identification AI has the capability to identify objects obfuscated by long-distance or objects better than a human could.</p>



<!-- Sign and date the page, it's only polite! -->

</body>
</html>